# Exemplo Pr√°tico de Otimiza√ß√£o

Este documento mostra EXATAMENTE como corrigir os pontos cr√≠ticos do `dashboard.py`.

---

## 1. Otimizar fun√ß√£o `salvar_produtos()` (linha ~225)

### ‚ùå ANTES (LENTO - usando iterrows)

```python
def salvar_produtos(df_editor):
    session = get_session()
    session.query(Produto).delete()

    for index, row in df_editor.iterrows():  # MUITO LENTO!
        if row['Nome do Produto']:
            p = Produto(
                nome=row['Nome do Produto'],
                palavras_chave=row['Palavras-Chave'],
                preco_custo=float(row['Pre√ßo de Custo']),
                margem_minima=float(row['Margem (%)']),
                preco_referencia=float(row.get('Pre√ßo Refer√™ncia', 0.0)),
                fonte_referencia=str(row.get('Fonte Refer√™ncia', ""))
            )
            session.add(p)
    session.commit()
    session.close()
    st.success("Cat√°logo atualizado!")
```

### ‚úÖ DEPOIS (R√ÅPIDO - usando bulk insert)

```python
def salvar_produtos(df_editor):
    session = get_session()
    session.query(Produto).delete()

    # Cria lista de produtos usando list comprehension
    produtos = []
    for row in df_editor.itertuples(index=False):  # MUITO MAIS R√ÅPIDO!
        if row[0]:  # Nome do Produto
            produtos.append(
                Produto(
                    nome=row[0],
                    palavras_chave=row[1],
                    preco_custo=float(row[2]),
                    margem_minima=float(row[3]),
                    preco_referencia=float(row[4] if len(row) > 4 else 0.0),
                    fonte_referencia=str(row[5] if len(row) > 5 else "")
                )
            )

    # Bulk insert - MUITO mais r√°pido
    session.bulk_save_objects(produtos)
    session.commit()
    session.close()

    st.success(f"Cat√°logo atualizado! {len(produtos)} produtos salvos.")
```

**Ganho: 10-30x mais r√°pido**

---

## 2. Adicionar Pagina√ß√£o em Tabelas (linhas 640, 1186, 1623)

### ‚ùå ANTES (TRAVA - renderiza tudo)

```python
st.dataframe(df_lancamentos)  # Se tiver 1000+ linhas, TRAVA!
```

### ‚úÖ DEPOIS (SUAVE - renderiza por partes)

```python
# Importar no topo do arquivo
from modules.utils.performance_helpers import paginate_dataframe

# Usar pagina√ß√£o
df_paginado = paginate_dataframe(df_lancamentos, page_size=50)
st.dataframe(df_paginado)
```

**Ganho: 10-50x mais r√°pido para tabelas grandes**

---

## 3. Adicionar Cache em Queries Frequentes

### ‚ùå ANTES (LENTO - reprocessa sempre)

```python
# No Dashboard
session = get_session()
licitacoes = session.query(Licitacao).filter(
    Licitacao.status == 'Nova'
).all()
session.close()
```

### ‚úÖ DEPOIS (R√ÅPIDO - usa cache)

```python
# Criar fun√ß√£o com cache (pode colocar no in√≠cio do arquivo)
@st.cache_data(ttl=300)  # Cache de 5 minutos
def load_licitacoes_novas():
    session = get_session()
    licitacoes = session.query(Licitacao).filter(
        Licitacao.status == 'Nova'
    ).all()

    # Converte para dict para poder cachear
    result = [
        {
            'id': lic.id,
            'orgao': lic.orgao,
            'objeto': lic.objeto,
            'status': lic.status,
            # ... outros campos
        }
        for lic in licitacoes
    ]
    session.close()
    return result

# Usar no c√≥digo
licitacoes = load_licitacoes_novas()
```

**Ganho: Queries instant√¢neas ap√≥s primeiro carregamento**

---

## 4. Otimizar Processamento de Extratos (linha ~1657)

### ‚ùå ANTES (LENTO)

```python
for lanc_id, row in edited_df.iterrows():  # LENTO!
    lanc = session.query(ExtratoBB).get(lanc_id)
    if lanc:
        lanc.tipo = row['tipo']
        lanc.status = row['status']
```

### ‚úÖ DEPOIS (R√ÅPIDO)

```python
# Prepara updates em lote
updates = []
for row in edited_df.itertuples():
    updates.append({
        'id': row.Index,
        'tipo': row.tipo,
        'status': row.status
    })

# Bulk update
session.bulk_update_mappings(ExtratoBB, updates)
```

**Ganho: 20-50x mais r√°pido**

---

## 5. Otimizar Parsing de Excel (extrato_parser.py linha ~77)

### ‚ùå ANTES (LENTO)

```python
for idx, row in df.iterrows():  # MUITO LENTO!
    try:
        lancamento = self._processar_linha(row, ...)
        if lancamento:
            lancamentos.append(lancamento)
    except Exception as e:
        self.erros.append(f"Erro na linha {idx}: {str(e)}")
```

### ‚úÖ DEPOIS (R√ÅPIDO)

```python
# Usa itertuples
for row in df.itertuples():
    try:
        # Acessa campos como row.Status, row.Hist√≥rico, etc.
        lancamento = self._processar_linha_tuple(row, ...)
        if lancamento:
            lancamentos.append(lancamento)
    except Exception as e:
        self.erros.append(f"Erro na linha {row.Index}: {str(e)}")
```

**Ganho: 10-20x mais r√°pido**

---

## 6. Template Completo de Otimiza√ß√£o

Copie e cole este template no in√≠cio do `dashboard.py`:

```python
import streamlit as st
import pandas as pd
from functools import lru_cache

# Importar helpers otimizados
from modules.utils.performance_helpers import (
    salvar_produtos_otimizado,
    paginate_dataframe,
    processar_dataframe_otimizado
)

# Cache de consultas frequentes
@st.cache_data(ttl=300)
def load_licitacoes_cached(status=None, limit=100):
    """Carrega licita√ß√µes com cache de 5 minutos"""
    session = get_session()
    query = session.query(Licitacao)

    if status:
        query = query.filter(Licitacao.status == status)

    query = query.order_by(Licitacao.data_captura.desc()).limit(limit)
    licitacoes = query.all()

    result = [
        {
            'id': l.id,
            'orgao': l.orgao,
            'objeto': l.objeto,
            'status': l.status,
            'data_captura': l.data_captura
        }
        for l in licitacoes
    ]
    session.close()
    return result

@st.cache_data(ttl=600)
def load_produtos_cached():
    """Carrega produtos com cache de 10 minutos"""
    session = get_session()
    produtos = session.query(Produto).all()

    result = [
        {
            'id': p.id,
            'nome': p.nome,
            'palavras_chave': p.palavras_chave,
            'preco_custo': p.preco_custo
        }
        for p in produtos
    ]
    session.close()
    return result

@st.cache_data(ttl=300)
def load_extratos_cached(mes=None, ano=None, limit=1000):
    """Carrega extratos com cache"""
    session = get_finance_session()
    query = session.query(ExtratoBB)

    if mes:
        query = query.filter(ExtratoBB.mes_referencia == mes)
    if ano:
        query = query.filter(ExtratoBB.ano_referencia == ano)

    query = query.limit(limit)
    extratos = query.all()

    result = [
        {
            'id': e.id,
            'dt_balancete': e.dt_balancete,
            'historico': e.historico,
            'valor': e.valor,
            'tipo': e.tipo
        }
        for e in extratos
    ]
    session.close()
    return result
```

---

## 7. Checklist de Implementa√ß√£o

- [ ] Backup do dashboard.py atual
- [ ] Adicionar imports dos helpers otimizados
- [ ] Substituir `salvar_produtos()` pela vers√£o otimizada
- [ ] Adicionar pagina√ß√£o em TODAS as tabelas grandes
- [ ] Adicionar `@st.cache_data` em todas as fun√ß√µes de consulta
- [ ] Substituir TODOS os `.iterrows()` por `.itertuples()` ou opera√ß√µes vetorizadas
- [ ] Testar cada mudan√ßa individualmente
- [ ] Executar `python scripts/performance_test.py` para confirmar melhorias

---

## 8. Como Testar

### Antes das mudan√ßas:
```bash
# Execute e anote o tempo
python scripts/performance_test.py
```

### Depois das mudan√ßas:
```bash
# Execute novamente e compare
python scripts/performance_test.py
```

### Teste no Streamlit:
```bash
streamlit run dashboard.py
```

Abra uma tabela grande e verifique se n√£o trava mais!

---

## üéØ Resultado Esperado

Ap√≥s implementar TODAS as otimiza√ß√µes:

| Opera√ß√£o | Antes | Depois | Melhoria |
|----------|-------|--------|----------|
| Salvar 100 produtos | 2-5s | 0.2s | 10-25x |
| Carregar tabela 1000 linhas | 5-10s | 0.5s | 10-20x |
| Query licita√ß√µes | 0.5s | 0.1s | 5x |
| Matching produtos | 2s | 0.4s | 5x |
| Parsing Excel | 10s | 2s | 5x |

**Total: Sistema 10-50x mais r√°pido!** üöÄ

---

## ‚ö†Ô∏è Dicas Importantes

1. **Fa√ßa uma mudan√ßa por vez** e teste
2. **Use Ctrl+C** para limpar cache do Streamlit quando necess√°rio
3. **Monitore o uso de mem√≥ria** - cache pode aumentar RAM
4. **Ajuste TTL do cache** se dados mudarem muito r√°pido
5. **Use `page_size=50`** para tabelas, ajuste conforme necess√°rio

---

**Boa sorte com as otimiza√ß√µes!** üöÄ
